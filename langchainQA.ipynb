{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPEN_API_KEY'] =KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of China is Beijing.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What is capital of China?\"\n",
    "llm.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USing Higgingface\n",
    "import os \n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "HUGGINGFACE_KEY = os.getenv(\"HUGGINGFACE_TOKEN_KEY\")\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] =HUGGINGFACE_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm_huggingface = HuggingFaceHub(repo_id ='google/flan-t5-large' ,model_kwargs = {'temperature':0 ,'max_length':128})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_huggingface.predict('bangladesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Artificial intelligence, a marvel of our time\n",
      "A creation of man, that's truly sublime\n",
      "With algorithms and codes, it learns and grows\n",
      "A digital brain, that constantly flows\n",
      "\n",
      "It mimics human thought, with precision and speed\n",
      "Solving problems, fulfilling our every need\n",
      "From self-driving cars to virtual assistants\n",
      "AI's capabilities, are truly persistent\n",
      "\n",
      "It analyzes data, in ways we cannot\n",
      "Predicting outcomes, with every single dot\n",
      "It can recognize faces, and even emotions\n",
      "A technology, with endless promotions\n",
      "\n",
      "But with great power, comes great responsibility\n",
      "For AI to be used, with utmost sensitivity\n",
      "For it is not just a machine, but a creation of ours\n",
      "To be used for good, and not for wars\n",
      "\n",
      "We must remember, it's still in our control\n",
      "To use AI for progress, and not for toll\n",
      "For it's a tool, to enhance our lives\n",
      "Not a replacement, for human drives\n",
      "\n",
      "So let us embrace, this wonder of our time\n",
      "But also be cautious, of its potential climb\n",
      "For AI may be intelligent, but we are still its guide\n",
      "Let us use it wisely, with humility and pride.\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict('Can you give a poem on AI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate #Help to define format of input and output\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me capital of India'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['Country'] ,\n",
    "    template = 'Tell me capital of {Country}'\n",
    ")\n",
    "prompt_template.format(Country ='India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of India is New Delhi.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm = llm ,prompt = prompt_template )\n",
    "op = chain({\n",
    "    'Country':'India'\n",
    "})\n",
    "chain.run(Country='India')\n",
    "# print(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combiine Multiple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=['Country'] ,\n",
    "    template = 'Tell me capital of {Country}'\n",
    ") \n",
    "capital_chain = LLMChain(llm=llm ,prompt=capital_prompt ,output_key='Capital')\n",
    "\n",
    "\n",
    "famous_places_prompt = PromptTemplate(\n",
    "    input_variables=['Capital'] ,\n",
    "    template = 'Suggest me amazing places to visist in {Capital} in proper list'\n",
    ") \n",
    "famous_places_chain = LLMChain(llm=llm ,prompt=famous_places_prompt ,output_key= 'Places')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': 'India',\n",
       " 'Capital': '\\nNew Delhi',\n",
       " 'Places': \"\\n\\n1. Red Fort\\n2. India Gate\\n3. Qutub Minar\\n4. Humayun's Tomb\\n5. Lotus Temple\\n6. Akshardham Temple\\n7. Chandni Chowk\\n8. Jama Masjid\\n9. Rashtrapati Bhavan\\n10. Connaught Place\\n11. Hauz Khas Village\\n12. Dilli Haat\\n13. Gurudwara Bangla Sahib\\n14. Nehru Planetarium\\n15. National Gallery of Modern Art\\n16. Lodhi Gardens\\n17. Raj Ghat\\n18. Delhi Zoo\\n19. National Handicrafts and Handlooms Museum\\n20. Chhatarpur Temple.\"}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = SequentialChain(\n",
    "    chains=[capital_chain ,famous_places_chain] ,\n",
    "    input_variables = ['Country'] ,\n",
    "    output_variables = ['Capital' ,'Places']\n",
    ")\n",
    "final_chain(\n",
    "    {\n",
    "        \"Country\" : 'India'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatmodel with ChatOpenAI :- \n",
    "for chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage ,SystemMessage ,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key=os.environ['OPEN_API_KEY']  ,model='gpt-3.5-turbo' ,temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Are you a computer program? Because every time I see you, my heart skips a byte.', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 24, 'total_tokens': 43}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a4a78435-7b5f-4bf4-8e75-ac4e0e27f19d-0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content='You are comedian AI assistant') ,\n",
    "    HumanMessage(content='Please provide some comedy pickup line on AI')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template +LLM + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.prompts.chat import ChatPromptTemplate \n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperateoutput(BaseOutputParser):\n",
    "    def parse(self ,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'You are helpful assistent. When the usee give any input you show 5 words synnonyms which are comma separated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template) ,\n",
    "    ('human', human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt | chatllm |Commaseperateoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' sharp', ' astute']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": 'intelligent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "###################################################################################################\n",
      "0 10\n",
      "1 12\n"
     ]
    }
   ],
   "source": [
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(\"#\".join('' for x in range(100)))\n",
    "name = \"Pramod Khavre\"\n",
    "\"-\".join(name)\n",
    "for i ,j in enumerate([10,12]):\n",
    "    print(i ,j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
